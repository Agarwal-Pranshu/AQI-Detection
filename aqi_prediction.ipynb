{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb06fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully\n",
      "Shape: (108035, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "      <th>StationName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>71.36</td>\n",
       "      <td>115.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>20.65</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.76</td>\n",
       "      <td>109.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secretariat, Amaravati - APPCB</td>\n",
       "      <td>Amaravati</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>127.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Secretariat, Amaravati - APPCB</td>\n",
       "      <td>Amaravati</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>117.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.08</td>\n",
       "      <td>197.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Secretariat, Amaravati - APPCB</td>\n",
       "      <td>Amaravati</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>111.81</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Secretariat, Amaravati - APPCB</td>\n",
       "      <td>Amaravati</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>138.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Secretariat, Amaravati - APPCB</td>\n",
       "      <td>Amaravati</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId        Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0     AP001  2017-11-24  71.36  115.75  1.75  20.65  12.40  12.19  0.10   \n",
       "1     AP001  2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "2     AP001  2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "3     AP001  2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "4     AP001  2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "\n",
       "     SO2      O3  Benzene  Toluene  Xylene    AQI AQI_Bucket  \\\n",
       "0  10.76  109.26     0.17     5.92    0.10    NaN        NaN   \n",
       "1  15.24  127.09     0.20     6.50    0.06  184.0   Moderate   \n",
       "2  26.96  117.44     0.22     7.95    0.08  197.0   Moderate   \n",
       "3  33.59  111.81     0.29     7.63    0.12  198.0   Moderate   \n",
       "4  19.00  138.18     0.17     5.02    0.07  188.0   Moderate   \n",
       "\n",
       "                      StationName       City           State  Status  \n",
       "0  Secretariat, Amaravati - APPCB  Amaravati  Andhra Pradesh  Active  \n",
       "1  Secretariat, Amaravati - APPCB  Amaravati  Andhra Pradesh  Active  \n",
       "2  Secretariat, Amaravati - APPCB  Amaravati  Andhra Pradesh  Active  \n",
       "3  Secretariat, Amaravati - APPCB  Amaravati  Andhra Pradesh  Active  \n",
       "4  Secretariat, Amaravati - APPCB  Amaravati  Andhra Pradesh  Active  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load datasets\n",
    "stations = pd.read_csv(\"stations.csv\")\n",
    "station_day = pd.read_csv(\"station_day.csv\")\n",
    "\n",
    "# Merge datasets on 'station'\n",
    "df = pd.merge(station_day, stations, on=\"StationId\", how=\"left\")\n",
    "\n",
    "print(\"Data Loaded Successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abab7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Summary:\n",
      "StationId          0\n",
      "Date               0\n",
      "PM2.5              0\n",
      "PM10               0\n",
      "NO              2229\n",
      "NO2                0\n",
      "NOx             4555\n",
      "NH3            29832\n",
      "CO                 0\n",
      "SO2                0\n",
      "O3                 0\n",
      "Benzene        19787\n",
      "Toluene        26324\n",
      "Xylene         67584\n",
      "AQI                0\n",
      "AQI_Bucket         0\n",
      "StationName        0\n",
      "City               0\n",
      "State              0\n",
      "Status           311\n",
      "dtype: int64\n",
      "Final Shape: (87025, 20)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Drop rows with missing target (AQI)\n",
    "df = df.dropna(subset=[\"AQI\"])\n",
    "\n",
    "# Fill numeric columns with median\n",
    "num_cols = [\"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\", \"O3\"]\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "cat_cols = [\"City\", \"State\"]\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Ensure types\n",
    "df[cat_cols] = df[cat_cols].astype(str)\n",
    "\n",
    "# Final check\n",
    "print(\"Cleaned Data Summary:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Final Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a959432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete â€” Train: (69620, 8) Test: (17405, 8)\n"
     ]
    }
   ],
   "source": [
    "# Select features and target\n",
    "features = [\"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\", \"O3\", \"City\", \"State\"]\n",
    "target = \"AQI\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Split complete â€” Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training Extra Trees...\n",
      "\n",
      "Extra Trees Results:\n",
      "RÂ²: 0.9190 | MAE: 21.28 | RMSE: 37.40\n",
      "Model saved as extra_trees_aqi.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Define feature types\n",
    "numeric_features = [\"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\", \"O3\"]\n",
    "categorical_features = [\"City\", \"State\"]\n",
    "\n",
    "# Numeric preprocessing\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical preprocessing\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine both preprocessors\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Create full Extra Trees pipeline\n",
    "et_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# Train\n",
    "print(\"ðŸ”¹ Training Extra Trees...\")\n",
    "et_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_et = et_pipeline.predict(X_test)\n",
    "r2_et = r2_score(y_test, y_pred_et)\n",
    "mae_et = mean_absolute_error(y_test, y_pred_et)\n",
    "rmse_et = np.sqrt(mean_squared_error(y_test, y_pred_et))\n",
    "\n",
    "print(f\"\\nExtra Trees Results:\")\n",
    "print(f\"RÂ²: {r2_et:.4f} | MAE: {mae_et:.2f} | RMSE: {rmse_et:.2f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(et_pipeline, \"extra_trees_aqi.pkl\")\n",
    "print(\"Model saved as extra_trees_aqi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afe42bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ST-Transformer (TensorFlow)...\n",
      "Epoch 1/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400us/step - loss: 7939.4839 - mae: 55.9256 - val_loss: 1257.8563 - val_mae: 25.3841\n",
      "Epoch 2/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385us/step - loss: 3994.5872 - mae: 41.7722 - val_loss: 1124.8641 - val_mae: 22.2539\n",
      "Epoch 3/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404us/step - loss: 3430.4199 - mae: 36.8815 - val_loss: 1080.1593 - val_mae: 20.7293\n",
      "Epoch 4/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 3170.3997 - mae: 34.7538 - val_loss: 1019.3242 - val_mae: 19.4798\n",
      "Epoch 5/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 3084.7217 - mae: 34.2389 - val_loss: 1125.8759 - val_mae: 21.6938\n",
      "Epoch 6/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 3053.7761 - mae: 33.9276 - val_loss: 1023.5617 - val_mae: 19.3902\n",
      "Epoch 7/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 3017.7490 - mae: 33.6697 - val_loss: 1081.3049 - val_mae: 20.4988\n",
      "Epoch 8/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 2996.2556 - mae: 33.3883 - val_loss: 1021.4470 - val_mae: 19.3456\n",
      "Epoch 9/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 2975.8318 - mae: 33.2682 - val_loss: 1043.5054 - val_mae: 19.5356\n",
      "Epoch 10/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 2956.8835 - mae: 33.0633 - val_loss: 1126.3018 - val_mae: 21.1226\n",
      "Epoch 11/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 2935.5017 - mae: 32.9754 - val_loss: 1017.6781 - val_mae: 19.1227\n",
      "Epoch 12/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 2938.9746 - mae: 32.9239 - val_loss: 1108.8292 - val_mae: 20.9367\n",
      "Epoch 13/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 2928.3528 - mae: 32.9215 - val_loss: 1076.7629 - val_mae: 20.2431\n",
      "Epoch 14/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 2937.1697 - mae: 32.9267 - val_loss: 1017.1061 - val_mae: 19.0800\n",
      "Epoch 15/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - loss: 2910.8306 - mae: 32.8071 - val_loss: 1078.0411 - val_mae: 19.6743\n",
      "Epoch 16/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 2903.1394 - mae: 32.7803 - val_loss: 1033.6796 - val_mae: 19.1531\n",
      "Epoch 17/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 2912.4729 - mae: 32.8344 - val_loss: 1120.6630 - val_mae: 20.9446\n",
      "Epoch 18/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 2912.8433 - mae: 32.7542 - val_loss: 999.4194 - val_mae: 18.6898\n",
      "Epoch 19/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 2894.0759 - mae: 32.7196 - val_loss: 1081.0210 - val_mae: 20.4018\n",
      "Epoch 20/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 2899.1733 - mae: 32.7388 - val_loss: 1087.9972 - val_mae: 20.7532\n",
      "Epoch 21/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - loss: 2892.3882 - mae: 32.6897 - val_loss: 1162.6851 - val_mae: 21.6193\n",
      "Epoch 22/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 2889.9167 - mae: 32.7021 - val_loss: 1049.8994 - val_mae: 19.0122\n",
      "Epoch 23/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 2889.8345 - mae: 32.6594 - val_loss: 1082.2968 - val_mae: 20.3175\n",
      "Epoch 24/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 2885.8333 - mae: 32.7121 - val_loss: 1092.9708 - val_mae: 20.1231\n",
      "Epoch 25/25\n",
      "\u001b[1m1956/1956\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367us/step - loss: 2881.1870 - mae: 32.6736 - val_loss: 1027.6274 - val_mae: 18.7316\n",
      "ST-Transformer training complete.\n",
      "\u001b[1m544/544\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step\n",
      "\n",
      "ST-Transformer Results:\n",
      "RÂ²: 0.8448 | MAE: 26.56 | RMSE: 40.75\n",
      "Model saved as st_transformer_aqi_tf.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Prepare data ---\n",
    "feature_cols = [\"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\", \"O3\"]\n",
    "X_seq = df[feature_cols].values\n",
    "y_seq = df[\"AQI_next\"].values\n",
    "\n",
    "# Split 80/20\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]\n",
    "y_train_seq, y_test_seq = y_seq[:split], y_seq[split:]\n",
    "\n",
    "# --- Define Transformer-like model using Dense layers ---\n",
    "def build_st_transformer(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "input_dim = len(feature_cols)\n",
    "model = build_st_transformer(input_dim)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# --- Training ---\n",
    "print(\"\\nTraining ST-Transformer (TensorFlow)...\")\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_split=0.1,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ST-Transformer training complete.\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred_st = model.predict(X_test_seq).flatten()\n",
    "\n",
    "r2_st = r2_score(y_test_seq, y_pred_st)\n",
    "mae_st = mean_absolute_error(y_test_seq, y_pred_st)\n",
    "rmse_st = np.sqrt(mean_squared_error(y_test_seq, y_pred_st))\n",
    "\n",
    "print(f\"\\nST-Transformer Results:\")\n",
    "print(f\"RÂ²: {r2_st:.4f} | MAE: {mae_st:.2f} | RMSE: {rmse_st:.2f}\")\n",
    "\n",
    "# --- Save model ---\n",
    "model.save(\"st_transformer_aqi_tf.keras\")\n",
    "print(\"Model saved as st_transformer_aqi_tf.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21792c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comparing Models...\n",
      "ST-Transformer â†’ RÂ²: 0.8448, MAE: 26.56, RMSE: 40.75\n",
      "Extra Trees    â†’ RÂ²: 0.9190, MAE: 21.28, RMSE: 37.40\n",
      "\n",
      " Best Model: Extra Trees (saved as best_model.pkl)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Comparing Models...\")\n",
    "\n",
    "print(f\"ST-Transformer â†’ RÂ²: {r2_st:.4f}, MAE: {mae_st:.2f}, RMSE: {rmse_st:.2f}\")\n",
    "print(f\"Extra Trees    â†’ RÂ²: {r2_et:.4f}, MAE: {mae_et:.2f}, RMSE: {rmse_et:.2f}\")\n",
    "\n",
    "if r2_st > r2_et:\n",
    "    best_model_name = \"ST-Transformer\"\n",
    "    joblib.dump({\"type\": \"STTransformer\", \"path\": \"st_transformer_aqi.pth\"}, \"best_model.pkl\")\n",
    "else:\n",
    "    best_model_name = \"Extra Trees\"\n",
    "    joblib.dump(et_pipeline, \"best_model.pkl\")\n",
    "\n",
    "print(f\"\\n Best Model: {best_model_name} (saved as best_model.pkl)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e75bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training Extra Trees model again...\n",
      "RÂ²: 0.9190\n",
      "MAE: 21.28\n",
      "RMSE: 37.40\n",
      "âœ… Exported best_model.joblib successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Features\n",
    "numeric_features = [\"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\", \"O3\"]\n",
    "categorical_features = [\"City\", \"State\"]\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "et_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"ðŸ”¹ Training Extra Trees model again...\")\n",
    "et_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = et_pipeline.predict(X_test)\n",
    "print(f\"RÂ²: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")\n",
    "\n",
    "# Export proper joblib bundle\n",
    "all_features = numeric_features + categorical_features\n",
    "joblib.dump(\n",
    "    {\"model\": et_pipeline, \"columns\": all_features},\n",
    "    \"best_model.joblib\",\n",
    "    compress=3\n",
    ")\n",
    "\n",
    "print(\"âœ… Exported best_model.joblib successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb018728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Cities:\n",
      "['Amaravati' 'Rajamahendravaram' 'Tirupati' 'Vijayawada' 'Visakhapatnam'\n",
      " 'Guwahati' 'Gaya' 'Hajipur' 'Muzaffarpur' 'Patna' 'Chandigarh' 'Delhi'\n",
      " 'Ahmedabad' 'Ankleshwar' 'Gandhinagar' 'Nandesari' 'Vapi' 'Vatva'\n",
      " 'Ambala' 'Bahadurgarh' 'Ballabgarh' 'Bhiwani' 'Dharuhera' 'Faridabad'\n",
      " 'Fatehabad' 'Gurugram' 'Hisar' 'Jind' 'Kaithal' 'Karnal' 'Kurukshetra'\n",
      " 'Mandikhera' 'Manesar' 'Narnaul' 'Palwal' 'Panchkula' 'Panipat' 'Rohtak'\n",
      " 'Sirsa' 'Sonipat' 'Yamuna Nagar' 'Jorapokhar' 'Bagalkot' 'Bengaluru'\n",
      " 'Chamarajanagar' 'Chikkaballapur' 'Chikkamagaluru' 'Hubballi'\n",
      " 'Kalaburagi' 'Mysuru' 'Ramanagara' 'Vijayapura' 'Yadgir' 'Eloor'\n",
      " 'Ernakulam' 'Kannur' 'Kochi' 'Kollam' 'Kozhikode' 'Thiruvananthapuram'\n",
      " 'Bhopal' 'Damoh' 'Dewas' 'Gwalior' 'Indore' 'Jabalpur' 'Katni' 'Maihar'\n",
      " 'Mandideep' 'Pithampur' 'Ratlam' 'Sagar' 'Satna' 'Singrauli' 'Ujjain'\n",
      " 'Aurangabad' 'Chandrapur' 'Kalyan' 'Mumbai' 'Nagpur' 'Nashik'\n",
      " 'Navi Mumbai' 'Pune' 'Solapur' 'Thane' 'Shillong' 'Aizawl' 'Brajrajnagar'\n",
      " 'Talcher' 'Amritsar' 'Bathinda' 'Jalandhar' 'Khanna' 'Ludhiana'\n",
      " 'Gobindgarh' 'Patiala' 'Rupnagar' 'Alwar' 'Ajmer' 'Bhiwandi' 'Jaipur'\n",
      " 'Jodhpur' 'Kota' 'Pali' 'Udaipur' 'Chennai' 'Coimbatore' 'Hyderabad'\n",
      " 'Agra' 'Baghpat' 'Bulandshahr' 'Ghaziabad' 'Greater Noida' 'Hapur'\n",
      " 'Kanpur' 'Lucknow' 'Meerut' 'Moradabad' 'Muzzaffarnagar' 'Noida'\n",
      " 'Varanasi' 'Asansol' 'Durgapur' 'Haldia' 'Howrah' 'Kolkata' 'Siliguri']\n",
      "\n",
      "Unique States:\n",
      "['Andhra Pradesh' 'Assam' 'Bihar' 'Chandigarh' 'Delhi' 'Gujarat' 'Haryana'\n",
      " 'Jharkhand' 'Karnataka' 'Kerala' 'Madhya Pradesh' 'Maharashtra'\n",
      " 'Meghalaya' 'Mizoram' 'Odisha' 'Punjab' 'Rajasthan' 'Tamil Nadu'\n",
      " 'Telangana' 'Uttar Pradesh' 'West Bengal']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (change filename if needed)\n",
    "df = pd.read_csv(\"stations.csv\")  # or pd.read_excel(\"your_file.xlsx\")\n",
    "\n",
    "# Get unique cities\n",
    "unique_cities = df[\"City\"].dropna().unique()\n",
    "\n",
    "# Get unique states\n",
    "unique_states = df[\"State\"].dropna().unique()\n",
    "\n",
    "print(\"Unique Cities:\")\n",
    "print(unique_cities)\n",
    "\n",
    "print(\"\\nUnique States:\")\n",
    "print(unique_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e417a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
